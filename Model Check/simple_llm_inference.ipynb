{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2e3aac-494b-4118-a85d-b0407042d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation in progress...\n",
      "Installation successful\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import site\n",
    "from pathlib import Path\n",
    "\n",
    "!echo \"Installation in progress...\"\n",
    "!{sys.executable} -m pip install -U transformers==4.35.2  --no-warn-script-location > /dev/null && echo \"Installation successful\" || echo \"Installation failed\"\n",
    "\n",
    "def get_python_version():\n",
    "    return \"python\" + \".\".join(map(str, sys.version_info[:2]))\n",
    "\n",
    "def set_local_bin_path():\n",
    "    local_bin = str(Path.home() / \".local\" / \"bin\") \n",
    "    local_site_packages = str(\n",
    "        Path.home() / \".local\" / \"lib\" / get_python_version() / \"site-packages\"\n",
    "    )\n",
    "    sys.path.append(local_bin)\n",
    "    sys.path.insert(0, site.getusersitepackages())\n",
    "    sys.path.insert(0, sys.path.pop(sys.path.index(local_site_packages)))\n",
    "\n",
    "set_local_bin_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca091bef-13b5-4ad8-aeb9-2abb98259e43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'intel_extension_for_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mintel_extension_for_pytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mipex\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaTokenizer, LlamaForCausalLM\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'intel_extension_for_pytorch'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "os.environ[\"SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS\"] = \"1\"\n",
    "os.environ[\"ENABLE_SDP_FUSION\"] = \"1\"\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "from ipywidgets import VBox, HBox, Button, Dropdown, IntSlider, FloatSlider, Text, Output, Label, Layout\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HTML\n",
    "\n",
    "\n",
    "# random seed\n",
    "if torch.xpu.is_available():\n",
    "    seed = 88\n",
    "    random.seed(seed)\n",
    "    torch.xpu.manual_seed(seed)\n",
    "    torch.xpu.manual_seed_all(seed)\n",
    "\n",
    "def select_device(preferred_device=None):\n",
    "    \"\"\"\n",
    "    Selects the best available XPU device or the preferred device if specified.\n",
    "\n",
    "    Args:\n",
    "        preferred_device (str, optional): Preferred device string (e.g., \"cpu\", \"xpu\", \"xpu:0\", \"xpu:1\", etc.). If None, a random available XPU device will be selected or CPU if no XPU devices are available.\n",
    "\n",
    "    Returns:\n",
    "        torch.device: The selected device object.\n",
    "        \"\"\"\n",
    "    try:\n",
    "        if preferred_device and preferred_device.startswith(\"cpu\"):\n",
    "            print(\"Using CPU.\")\n",
    "            return torch.device(\"cpu\")\n",
    "        if preferred_device and preferred_device.startswith(\"xpu\"):\n",
    "            if preferred_device == \"xpu\" or (\n",
    "                \":\" in preferred_device\n",
    "                and int(preferred_device.split(\":\")[1]) >= torch.xpu.device_count()\n",
    "            ):\n",
    "                preferred_device = (\n",
    "                    None  # Handle as if no preferred device was specified\n",
    "                )\n",
    "            else:\n",
    "                device = torch.device(preferred_device)\n",
    "                if device.type == \"xpu\" and device.index < torch.xpu.device_count():\n",
    "                    vram_used = torch.xpu.memory_allocated(device) / (\n",
    "                        1024**2\n",
    "                    )  # In MB\n",
    "                    print(\n",
    "                        f\"Using preferred device: {device}, VRAM used: {vram_used:.2f} MB\"\n",
    "                    )\n",
    "                    return device\n",
    "\n",
    "        if torch.xpu.is_available():\n",
    "            device_id = random.choice(\n",
    "                range(torch.xpu.device_count())\n",
    "            )  # Select a random available XPU device\n",
    "            device = torch.device(f\"xpu:{device_id}\")\n",
    "            vram_used = torch.xpu.memory_allocated(device) / (1024**2)  # In MB\n",
    "            print(f\"Selected device: {device}, VRAM used: {vram_used:.2f} MB\")\n",
    "            return device\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while selecting the device: {e}\")\n",
    "    print(\"No XPU devices available or preferred device not found. Using CPU.\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adca10-ff4f-4ff2-bca2-c46777d03160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
